<h1>Incomplete Draft</h1>

<h3>The Importance Of A Tight Code-Test-Deploy Loop</h3>

A developer should seek to minimize the duration of their code-test-deploy loop cycle. As software grows, it is inevitable this to end-to-end process grows longer and more complicated. Most of us know the joy of starting a new project and feeling the rush of rapid iteration: make a code change, and run it instantly, and repeat. The project is small, compilation times are fast, and correctness is verified by just running the program. A simple git push suffices as a deployment for quite awhile.

We've also experienced the opposite. You inherent a huge and complicated code base and are asked to make a change. There are no unit tests. When you ask your team how to run the code locally, you are told it is impossible because it depends on several production systems that do not exist locally or in a seperate development environment. Even when you make a code change - you do not know if that change is correct or how it will effect the rest of the system. I believe this is a large source of "tribal knowledge" within companies - the undocumented tips and tricks developers know how to run and test the software efficiently. This is not intentional, and I have experienced it with code bases I have developed myself upon handing the code over to a teammate. I have undocumented knowledge of the code base's code-test-deploy loop cycle that makes me best suited to work on it, both in the amount of time it takes to make a change, and the chance the change I make is correct.

The story of the 10x or 100x programmer is a popular one in the software engineering field, but with a bit of quantification it is not hard how to see it could be true.

Let's say two developers are asked to make the same change on the same codebase. Developer Bob has worked on the code base before, and is familiar with how to test the code base subsystems in an independent fashion. Bob is also skilled in refactoring large systems into smaller subsystems to test and run independently. Bob recognizes that if he can minimize the duration of his code-test cycle, he can finish the feature faster. Upon examining the change he has to make, he makes an important refactor to allow him to more quickly test his change in isolation. Bob is a pretty smart guy not prone to making silly coding mistakes, and it will take him 50 code-test cycles to implement the feature correctly which can be attributed because of his refactor and previous knowledge of the system, each code-test cycle takes 5 minutes on average. Bob finishes the feature in 250 minutes. 

Now the other developer Joe has never worked on this code base before. Immediately Joe incurs a 4 hour penalty just reading the code and figuring out where to make the change, and how to test the change locally. Joe is not great at refactoring or testing, and he has trouble isolating the subsytem he tests, resulting in a much longer test process that quickly becomes a bottleneck during verification. Additionally, Joe just is not as sharp as Bob on this day, and he finds himself making silly errors that are slowing him down. It requires Joe 120 code-test cycles at an average time of 8 minutes each. Joe finishes the feature in 1200 minutes, 4.8X slower than Bob. Joe also does not deliver any refactoring changes, actually leaving at least as complicated as before.

This is a totally contrived example, but I do not feel it is unrealistic. The next time Joe works on the same codebase he would not incur that initial 4 hour penalty, but his inability to minimize the code-test cycle as efficiently, in additional to his carelessness while programming, Bob is always going to be less efficient than Joe, by possibily an order of magnitude. 100x feels unrealstic to me, but 10x appears feasible. 

What I really want to focus on here is the code-test loop, because this is the critical process a developer performs tens to hundreds to thousands of times before a feature is complete. A certain number of iterations is always going to be required to get a feature right, and the faster a change is made and tested is absolutely critical to efficiency. A strong developer finds ways to minimize the duration of the code-test loop, and identifies that the minimization of the code-test loop is actually the most efficient way to deliver the feature or future features. Futhermore, the strong developer will be praised for his architectural prowess and ability to not only deliver, but also to transform the code and the process into something fundamentally better. However, a strong developer also recognizes when such architectural refactoring is necessary and when it is not. Sometimes the code-test loop is fast enough, and while it could be improved, is not really necessary overall. As often is with programming, there are no hard rules. Every situation is different with differing requirements. 

I would personally be interested in software engineering reseach where programmers are given a task and attempt to measure the code-test loop, and observe what steps a developer takes to optimize the loop, and see how this effects both the duration to complete the task, and the overall architecture of the solution.

It is also worth mentioning that a lot of developer work is not coding, but investigating. It is somewhat unglorious to parse through logs for days trying to figure out a problem. Good developers have a pattern here: they create a hypothesis, and create run tests to verify or confirm that hypothesis. Good developers make code changes to verify their hypothesis - often times this is the form of additional logging. Bad developers flounder around trying to find the root cause to problems: thier idea of a hypothesis is vague, and they randomly make changes hoping something sticks. After awhile they forget what they've tried and what they haven't, and they end up wasting time repeating the same bad processes over and over. A good developer learns something from each failed hypothesis, and they use this knowledge as input into their next hypothesis: it is the scientific process. 

A good developer also makes less assumptions than a bad developer from the start.

Once we move into the land of deployment, the code-test loop becomes the code-test-deploy loop, and effeciency depends not only on the developer but on the engineering system and organization as whole. For example:

1) Does there exist development and/or staging environments where devs can safely test changes against live systems?
2) What is the deployment model like? Is there a ringed deployment to reduce the risk of a bad change affecting all users at once? Such models encourage faster deployment cadence
3) How does the deployment of one system affect the others? Is deployment complicated because multiple systems must be brought offline at the same time?


Because it is vague, what is a realitic example of refactoring into smaller subsystems? From my own experience this usually involves pulling out code into smaller functions or classes:

1) Identify common functionality throughout the code and move the logic into its own class. For example, maybe the code is commonly monitoring the state of the Windows event log, so you create a WindowsEventLogMonitor class that pulls disparate logic into a single place. 

2) Refactor unpure functions into a series of calls to pure functions. Pure functions are easy to test and verify. 
